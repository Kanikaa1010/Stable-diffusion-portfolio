{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Stable Diffusion Portfolio Project - Basic Text-to-Image Generation\n",
        "\n",
        "This notebook demonstrates the basic text-to-image generation capabilities of Stable Diffusion 1.5. You'll learn how to:\n",
        "- Set up the environment (imported from base template)\n",
        "- Download and initialize the Stable Diffusion model\n",
        "- Generate images from text prompts\n",
        "- Configure basic generation parameters\n",
        "- Save and display results\n",
        "\n",
        "**Author:** [Your Name]\n",
        "**Date:** [Current Date]\n",
        "**Version:** 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, we'll set up our environment using the base template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive-mount"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define project directory in Google Drive\n",
        "PROJECT_DIR = '/content/drive/MyDrive/stable-diffusion-portfolio'\n",
        "\n",
        "# Create project directory if it doesn't exist\n",
        "if not os.path.exists(PROJECT_DIR):\n",
        "    os.makedirs(PROJECT_DIR)\n",
        "    print(f\"Created project directory at {PROJECT_DIR}\")\n",
        "else:\n",
        "    print(f\"Project directory exists at {PROJECT_DIR}\")\n",
        "\n",
        "# Create subdirectories for organization\n",
        "subdirs = ['models', 'outputs', 'configs', 'data']\n",
        "for subdir in subdirs:\n",
        "    path = os.path.join(PROJECT_DIR, subdir)\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        print(f\"Created {subdir} directory\")\n",
        "    else:\n",
        "        print(f\"{subdir} directory exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q diffusers==0.27.0 \\\n",
        "    transformers>=4.30.0 \\\n",
        "    accelerate>=0.20.0 \\\n",
        "    torch>=2.0.0 \\\n",
        "    Pillow>=9.0.0 \\\n",
        "    numpy>=1.22.0 \\\n",
        "    huggingface-hub>=0.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "standard-imports"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import warnings\n",
        "\n",
        "# Specific imports for Diffusers\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers.utils import make_image_grid\n",
        "\n",
        "# Configure warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Set default figure size for matplotlib\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify-gpu"
      },
      "outputs": [],
      "source": [
        "def check_gpu():\n",
        "    \"\"\"Check if GPU is available and display information.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"GPU is available! Found {gpu_count} GPU(s)\")\n",
        "        for i in range(gpu_count):\n",
        "            device_name = torch.cuda.get_device_name(i)\n",
        "            print(f\"GPU {i}: {device_name}\")\n",
        "        \n",
        "        # Get CUDA version\n",
        "        cuda_version = torch.version.cuda\n",
        "        print(f\"CUDA Version: {cuda_version}\")\n",
        "        \n",
        "        # Memory info\n",
        "        print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        print(f\"Allocated GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "        print(f\"Cached GPU memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
        "        \n",
        "        return True\n",
        "    else:\n",
        "        print(\"GPU is NOT available. This notebook will run on CPU which is significantly slower.\")\n",
        "        print(\"Go to Runtime > Change runtime type and select GPU as the hardware accelerator.\")\n",
        "        return False\n",
        "\n",
        "# Check GPU\n",
        "has_gpu = check_gpu()\n",
        "\n",
        "# Set device for PyTorch\n",
        "device = torch.device(\"cuda\" if has_gpu else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-loading-section"
      },
      "source": [
        "## 2. Download and Initialize Stable Diffusion Model\n",
        "\n",
        "We'll initialize the Stable Diffusion v1.5 model from Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],

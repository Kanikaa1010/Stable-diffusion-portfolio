{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Stable Diffusion Quick Test\n",
        "\n",
        "This is a minimal test notebook to verify Stable Diffusion works in your Colab environment.\n",
        "\n",
        "Steps:\n",
        "1. Setup Google Drive\n",
        "2. Install dependencies\n",
        "3. Load model\n",
        "4. Generate an image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drive_setup"
      },
      "source": [
        "## 1. Drive Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code mounts the Google Drive to Google Colab, allowing **access to the  files**. It then creates a specified project directory if it doesnâ€™t already exist, ensuring a consistent location to save or load data, models, and other project files."
      ],
      "metadata": {
        "id": "qLTXRAVpPJMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a project folder\n",
        "import os\n",
        "project_dir = '/content/drive/MyDrive/sd_test'\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "print(f\"Project directory: {project_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dependencies"
      },
      "source": [
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command installs essential machine learning libraries: **diffusers** for image generation, **transformers** for pre-trained models, **accelerate** for device optimization, and **torch** for deep\n",
        "learning. These tools are commonly used for creating, training, and\n",
        "running AI models efficiently in Colab."
      ],
      "metadata": {
        "id": "-lWUyGa4PvwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## explain all libraries"
      ],
      "metadata": {
        "id": "gEp7mhrfIPJq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q diffusers transformers accelerate torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu_check"
      },
      "source": [
        "## 3. GPU Check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both codes check device availability, **torch needs manual setup, while accelerate auto-selects the best device (CPU/GPU/TPU) and simplifies deployment**. My finding: **accelerate is more efficient and better suited for scalable, multi-device model training in real-world projects.**"
      ],
      "metadata": {
        "id": "RPArIjTN6Fqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"GPU not available, using CPU\")'''"
      ],
      "metadata": {
        "id": "GnkyuM5T5IZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "device = accelerator.device\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_model"
      },
      "source": [
        "## 4. Load Stable Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both codes load the **Stable Diffusion model**. The **first uses torch to manually check and assign GPU/CPU, while the second uses accelerate to automatically manage the best available device**. My finding: accelerate offers a cleaner, more scalable approach, especially for larger models or multi-device setups."
      ],
      "metadata": {
        "id": "NRPxamcq8AqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# Load model\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ")\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "print(\"Model loaded successfully!\")'''"
      ],
      "metadata": {
        "id": "V17oi4Mpdtz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_sd_model"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Initialize accelerator\n",
        "accelerator = Accelerator()\n",
        "device = accelerator.device\n",
        "\n",
        "# Load model\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ")\n",
        "\n",
        "# Move model to correct device\n",
        "pipe.to(device)\n",
        "\n",
        "print(f\"Model loaded successfully on device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generate_image"
      },
      "source": [
        "## 5. Generate Test Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code generates an **image from a text** prompt using the Stable Diffusion model. It tracks generation time, displays the image in Colab, and saves it to Google Drive. It demonstrates prompt-to-image conversion and model inference with output storage."
      ],
      "metadata": {
        "id": "g3DotFpm9L2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_test_image"
      },
      "outputs": [],
      "source": [
        "# Set prompt\n",
        "prompt = \"A beautiful sunset over mountains, high quality, detailed\"\n",
        "\n",
        "# Generate image\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Image generated in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Display image\n",
        "display(image)\n",
        "\n",
        "# Save image\n",
        "save_path = os.path.join(project_dir, \"test_image.png\")\n",
        "image.save(save_path)\n",
        "print(f\"Image saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "try_another"
      },
      "source": [
        "## 6. Try Your Own Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code generates an **AI image from a custom prompt using Stable Diffusion**. It uses **generator for reproducibility**, **num_inference_steps to balance speed and detail**, and **guidance_scale to control prompt accuracy**. The final image is displayed and saved with a timestamped filename in Google Drive."
      ],
      "metadata": {
        "id": "z7CN-lmW-tJ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_prompt"
      },
      "outputs": [],
      "source": [
        "# Enter your prompt\n",
        "custom_prompt = \"A futuristic city with flying cars and tall skyscrapers, digital art\"  # Change this to your prompt\n",
        "\n",
        "# Set seed for reproducibility (optional)\n",
        "generator = torch.Generator(device=device).manual_seed(42)  # Change the seed value as desired\n",
        "\n",
        "# Generate image\n",
        "image = pipe(\n",
        "    custom_prompt,\n",
        "    generator=generator,\n",
        "    num_inference_steps=30,  # Default is 50, lower = faster\n",
        "    guidance_scale=7.5  # How closely to follow the prompt (default is 7.5)\n",
        ").images[0]\n",
        "\n",
        "# Display image\n",
        "display(image)\n",
        "\n",
        "# Save image\n",
        "import datetime\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = os.path.join(project_dir, f\"custom_image_{timestamp}.png\")\n",
        "image.save(save_path)\n",
        "print(f\"Image saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your prompt\n",
        "custom_prompt = \"A futuristic city with flying cars and tall skyscrapers, digital art\"  # Change this to your prompt\n",
        "\n",
        "# Set seed for reproducibility (optional)\n",
        "generator = torch.Generator(device=device).manual_seed(42)  # Change the seed value as desired\n",
        "\n",
        "# Generate image\n",
        "image = pipe(\n",
        "    custom_prompt,\n",
        "    generator=generator,\n",
        "    num_inference_steps=300,  # Default is 50, lower = faster\n",
        "    guidance_scale=8  # How closely to follow the prompt (default is 7.5)\n",
        ").images[0]\n",
        "\n",
        "# Display image\n",
        "display(image)\n",
        "\n",
        "# Save image\n",
        "import datetime\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = os.path.join(project_dir, f\"custom_image_{timestamp}.png\")\n",
        "image.save(save_path)\n",
        "print(f\"Image saved to {save_path}\")"
      ],
      "metadata": {
        "id": "9lNFysiDW_RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "def generate_and_compare_images(pipe, prompt, project_dir, device, steps_list, guidance_list, seed=42):\n",
        "    \"\"\"\n",
        "    Generate and display images for different combinations of inference steps and guidance scale.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(len(steps_list), len(guidance_list), figsize=(5 * len(guidance_list), 5 * len(steps_list)))\n",
        "\n",
        "    for i, steps in enumerate(steps_list):\n",
        "        for j, guidance in enumerate(guidance_list):\n",
        "            generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "            image = pipe(\n",
        "                prompt,\n",
        "                generator=generator,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=guidance\n",
        "            ).images[0]\n",
        "\n",
        "            # Save the image\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"image_steps{steps}_guidance{guidance}_{timestamp}.png\"\n",
        "            save_path = os.path.join(project_dir, filename)\n",
        "            image.save(save_path)\n",
        "\n",
        "            # Display image\n",
        "            axes[i, j].imshow(image)\n",
        "            axes[i, j].axis('off')\n",
        "            axes[i, j].set_title(f\"Steps: {steps}, Guidance: {guidance}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "YHjOJdviJx_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"Sunset at Golden Gate Bridge\"\n",
        "\n",
        "# Define parameter lists\n",
        "steps_list = [100,200,400,800,1600]              # Try more values for deeper comparison\n",
        "guidance_list = [3.0, 6.0, 9.0]   # Try strict vs. loose prompt adherence\n",
        "\n",
        "generate_and_compare_images(pipe, custom_prompt, project_dir, device, steps_list, guidance_list)\n"
      ],
      "metadata": {
        "id": "xRR62oYY4g3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make a function which can hold multiple parameters for image generation and display results in a comparative manner"
      ],
      "metadata": {
        "id": "YM-_p3yAKFh4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "stable_diffusion_test.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
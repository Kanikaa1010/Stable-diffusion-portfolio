{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2sGbT38IlaOyUp45jqmHi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6656c58fc844afa9a7f9814573ed3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6c3f47fde8b4de681024a83ca38767b",
              "IPY_MODEL_0a8e71a1375847c9afd316b5801fda97",
              "IPY_MODEL_b19eacbaa78b48f28746d0a341e54254"
            ],
            "layout": "IPY_MODEL_c44c4d19cf6440b09a6afd7785e7ff9f"
          }
        },
        "c6c3f47fde8b4de681024a83ca38767b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8afca14b13a546f7b3a81fc81097c92f",
            "placeholder": "​",
            "style": "IPY_MODEL_3318b996cb05435a850210998421b5b2",
            "value": ""
          }
        },
        "0a8e71a1375847c9afd316b5801fda97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5beea607f2a041029c53c5291bacb8a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d51a928d5474b8283c5cde8251c74a6",
            "value": 0
          }
        },
        "b19eacbaa78b48f28746d0a341e54254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e7adaa06d841d48ddf6c6d6e8fa6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_23a3d20b19c14dc8a171dbc00d53658d",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "c44c4d19cf6440b09a6afd7785e7ff9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8afca14b13a546f7b3a81fc81097c92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3318b996cb05435a850210998421b5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5beea607f2a041029c53c5291bacb8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5d51a928d5474b8283c5cde8251c74a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10e7adaa06d841d48ddf6c6d6e8fa6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a3d20b19c14dc8a171dbc00d53658d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanikaa1010/Stable-diffusion-portfolio/blob/main/notebooks/SD_V3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# SD_V3.1.1"
      ],
      "metadata": {
        "id": "WmPkYGtczati"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PIP Installs\n",
        "\n",
        "!pip install -q huggingface_hub==0.16.4 diffusers==0.21.4 transformers==4.32.1 accelerate==0.21.0 torch==2.0.1\n",
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 diffusers transformers accelerate numpy --upgrade\n"
      ],
      "metadata": {
        "id": "YPBFxdPL2qwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs AI Tools: This code downloads and sets up essential Python libraries (like diffusers and transformers) often used for running AI models."
      ],
      "metadata": {
        "id": "TfFS7UUWr0u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title   Import libraries and define basic functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Memory optimization function\n",
        "def optimize_memory():\n",
        "    \"\"\"Free up GPU memory\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    print(\"Memory optimized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "b6656c58fc844afa9a7f9814573ed3a0",
            "c6c3f47fde8b4de681024a83ca38767b",
            "0a8e71a1375847c9afd316b5801fda97",
            "b19eacbaa78b48f28746d0a341e54254",
            "c44c4d19cf6440b09a6afd7785e7ff9f",
            "8afca14b13a546f7b3a81fc81097c92f",
            "3318b996cb05435a850210998421b5b2",
            "5beea607f2a041029c53c5291bacb8a8",
            "5d51a928d5474b8283c5cde8251c74a6",
            "10e7adaa06d841d48ddf6c6d6e8fa6cf",
            "23a3d20b19c14dc8a171dbc00d53658d"
          ]
        },
        "id": "SBAgi9AS1OaF",
        "outputId": "e6adb202-1d89-4ac0-824c-302b9ed0dbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6656c58fc844afa9a7f9814573ed3a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Sets up for AI Tasks**: The code imports various tools and libraries like torch (for AI computations), PIL (for images), and nltk (for text processing), and defines a function to free up memory.\n",
        "* **Downloads Data**: It downloads necessary data for the nltk library, used for text analysis.\n",
        "* **Memory Management**: It includes a function optimize_memory to clear up GPU memory, which is useful when working with large AI models to prevent crashes.\n",
        "\n"
      ],
      "metadata": {
        "id": "VFIme9Pcstw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Stable Diffusion with memory optimizations\n",
        "def initialize_stable_diffusion():\n",
        "    # Create directories\n",
        "    project_dir = \"./sd_project\"\n",
        "    images_dir = os.path.join(project_dir, \"images\")\n",
        "    os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "    # Determine device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load the model with memory optimization\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        revision=\"fp16\" if device == \"cuda\" else \"main\",\n",
        "        use_safetensors=True,\n",
        "    )\n",
        "\n",
        "    # Apply memory optimizations\n",
        "    if device == \"cuda\":\n",
        "        pipe.enable_attention_slicing(1)  # Slice attention to reduce memory\n",
        "\n",
        "    # Move to device\n",
        "    pipe = pipe.to(device)\n",
        "\n",
        "    print(\"Model loaded successfully\")\n",
        "    return pipe, images_dir\n",
        "\n",
        "# Initialize model\n",
        "pipe, images_dir = initialize_stable_diffusion()"
      ],
      "metadata": {
        "id": "G384vz-t1Rqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Loads AI Image Generator: Sets up the Stable Diffusion model to generate images from text prompts using pre-trained weights.\n",
        "\n",
        "⚙️ Device Selection: Automatically chooses GPU (if available) for faster processing, otherwise falls back to CPU.\n",
        "\n",
        "💾 Memory Optimization: Uses attention slicing — a technique that splits attention computation into tiny parts *(slicing=1)* to save GPU memory at the cost of a bit of speed. This is essential for running large models on limited hardware.\n",
        "\n",
        "🚀 Ready to Use: The function returns a ready pipeline and a folder path to save generated images."
      ],
      "metadata": {
        "id": "p73Buzpntpzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Create a simplified prompt enhancer\n",
        "def enhance_prompt(prompt, quality_level=\"high\"):\n",
        "    \"\"\"Enhance a prompt with quality descriptors\"\"\"\n",
        "    quality_descriptors = {\n",
        "        \"low\": \"good quality\",\n",
        "        \"medium\": \"high quality, detailed\",\n",
        "        \"high\": \"high quality, detailed, sharp focus, 8k\",\n",
        "        \"ultra\": \"masterpiece, best quality, ultra detailed, 8k HDR, sharp focus\"\n",
        "    }\n",
        "\n",
        "    # Get quality descriptor\n",
        "    quality = quality_descriptors.get(quality_level, quality_descriptors[\"high\"])\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced = f\"{prompt}, {quality}\"\n",
        "    return enhanced\n",
        "\n",
        "# Create a simplified negative prompt generator\n",
        "def create_negative_prompt():\n",
        "    \"\"\"Create a standard negative prompt\"\"\"\n",
        "    return (\"deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, \"\n",
        "            \"extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, \"\n",
        "            \"ugly, disgusting, blurry, low quality\")"
      ],
      "metadata": {
        "id": "gBpCk1451TQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Improves Prompts:** The code defines functions to enhance the text prompts given to the AI model.\n",
        "* **Quality Levels:** The enhance_prompt function adds quality descriptors (like \"high quality\" or \"8k\") based on the chosen level.\n",
        "* **Negative Prompts:** The create_negative_prompt function generates a standard \"negative prompt\" (things to avoid in the image, like deformities) to improve image quality."
      ],
      "metadata": {
        "id": "O-0angwcvOPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Basic image generation function\n",
        "def generate_image(pipe, prompt, negative_prompt=None, steps=30, guidance=7.5, height=512, width=512):\n",
        "    \"\"\"Generate an image with Stable Diffusion\"\"\"\n",
        "\n",
        "    # Use default negative prompt if none provided\n",
        "    if negative_prompt is None:\n",
        "        negative_prompt = create_negative_prompt()\n",
        "\n",
        "    # Optimize memory before generation\n",
        "    optimize_memory()\n",
        "\n",
        "    # Generate image\n",
        "    start_time = time.time()\n",
        "    print(f\"Generating image with {steps} steps...\")\n",
        "\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "        height=height,\n",
        "        width=width\n",
        "    ).images[0]\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Image generated in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    return image\n",
        "\n",
        "# Save image function\n",
        "def save_image(image, images_dir, filename=None, prompt=None):\n",
        "    \"\"\"Save an image with optional metadata\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"image_{timestamp}.png\"\n",
        "\n",
        "    save_path = os.path.join(images_dir, filename)\n",
        "    image.save(save_path)\n",
        "\n",
        "    # Save prompt as text file if provided\n",
        "    if prompt:\n",
        "        text_path = save_path.replace('.png', '_prompt.txt')\n",
        "        with open(text_path, 'w') as f:\n",
        "            f.write(prompt)\n",
        "\n",
        "    print(f\"Image saved to {save_path}\")\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "fI2_z0Kh1UfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Generates Images:** The code defines a generate_image function that takes a text prompt and uses the Stable Diffusion model to create an image.\n",
        "* **Customization:** You can control image generation with parameters like the number of steps, image size, and how closely the image should match the prompt. It also uses a negative prompt to specify what to avoid in the image.\n",
        "* **Memory Optimization:** It calls optimize_memory before generating each image.\n",
        "* **Saves Images:** The save_image function saves the generated images to a specified directory, optionally including the original prompt in a text file."
      ],
      "metadata": {
        "id": "KneR7iKnz11E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test single image generation\n",
        "try:\n",
        "    # Use a simple prompt\n",
        "    prompt = \"A small cottage in the forest\"\n",
        "    print(f\"Original prompt: {prompt}\")\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced_prompt = enhance_prompt(prompt, \"medium\")  # Medium for less complexity\n",
        "    print(f\"Enhanced prompt: {enhanced_prompt}\")\n",
        "\n",
        "    # Generate negative prompt\n",
        "    negative_prompt = create_negative_prompt()\n",
        "    print(f\"Using standard negative prompt\")\n",
        "\n",
        "    # Generate image (with small size for testing)\n",
        "    image = generate_image(\n",
        "        pipe=pipe,\n",
        "        prompt=enhanced_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        steps=20,  # Lower steps for quicker generation\n",
        "        height=384,  # Smaller size to conserve memory\n",
        "        width=384\n",
        "    )\n",
        "\n",
        "    # Save and display the image\n",
        "    save_image(image, images_dir, prompt=enhanced_prompt)\n",
        "    from IPython.display import display\n",
        "    display(image)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in image generation: {e}\")\n",
        "\n",
        "    # If it fails, try with absolute minimal settings\n",
        "    try:\n",
        "        print(\"Attempting with minimal settings...\")\n",
        "        optimize_memory()\n",
        "\n",
        "        minimal_image = pipe(\n",
        "            prompt=\"Forest cottage\",\n",
        "            num_inference_steps=15,\n",
        "            height=256,\n",
        "            width=256\n",
        "        ).images[0]\n",
        "\n",
        "        save_image(minimal_image, images_dir, filename=\"minimal_test.png\")\n",
        "        display(minimal_image)\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"Even minimal settings failed: {e2}\")\n",
        "        print(\"Your Colab environment may not have enough GPU resources for Stable Diffusion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lASsc4Ev1XBE",
        "outputId": "49b6db2e-aba4-467e-e925-548c59bd8b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original prompt: A small cottage in the forest\n",
            "Enhanced prompt: A small cottage in the forest, high quality, detailed\n",
            "Using standard negative prompt\n",
            "Error in image generation: name 'pipe' is not defined\n",
            "Attempting with minimal settings...\n",
            "Memory optimized\n",
            "Even minimal settings failed: name 'pipe' is not defined\n",
            "Your Colab environment may not have enough GPU resources for Stable Diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Tests Image Generation:** This code block attempts to generate and display a single image using the defined functions.\n",
        "* **Prompt Enhancement:** It uses the enhance_prompt function to improve the initial prompt.\n",
        "* **Error Handling:** If the initial image generation fails (due to memory issues or other problems), it tries again with much simpler settings to ensure the core functionality works.\n",
        "* **Image Display:** It saves the generated image and displays it within the environment (like a Jupyter Notebook or Google Colab)."
      ],
      "metadata": {
        "id": "Ie2Uy1MG0JfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Simple parameter comparison\n",
        "# Only run this if Step 6 succeeded\n",
        "\n",
        "try:\n",
        "    print(\"\\nCreating simple parameter comparison...\")\n",
        "    optimize_memory()\n",
        "\n",
        "    # Use a very simple prompt\n",
        "    simple_prompt = \"Mountain landscape\"\n",
        "\n",
        "    # Test different step counts (keeping everything else minimal)\n",
        "    steps_to_test = [15, 30]\n",
        "    images = []\n",
        "\n",
        "    for steps in steps_to_test:\n",
        "        print(f\"Generating with {steps} steps...\")\n",
        "        img = pipe(\n",
        "            prompt=simple_prompt,\n",
        "            negative_prompt=create_negative_prompt(),\n",
        "            num_inference_steps=steps,\n",
        "            height=384,\n",
        "            width=384\n",
        "        ).images[0]\n",
        "\n",
        "        images.append(img)\n",
        "        save_image(img, images_dir, filename=f\"steps_{steps}.png\")\n",
        "\n",
        "    # Display comparison\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 6))\n",
        "\n",
        "    for i, (img, steps) in enumerate(zip(images, steps_to_test)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Steps: {steps}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(images_dir, \"steps_comparison.png\"))\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Parameter comparison failed: {e}\")\n",
        "    print(\"Try running with even smaller settings or on CPU\")"
      ],
      "metadata": {
        "id": "382ZgQFo1YiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Compares Image Quality:** This code tests how different settings (specifically, the number of steps) affect the quality of the generated images.\n",
        "* **Iterative Generation:** It generates multiple images using the same prompt but with varying numbers of \"steps\" (a setting that affects image quality).\n",
        "* **Visual Comparison:** It then displays these generated images side-by-side using Matplotlib, making it easy to see the impact of changing the \"steps\" parameter.\n",
        "* **Error Handling:** Includes a try...except block to handle potential issues during image generation and provides suggestions for troubleshooting."
      ],
      "metadata": {
        "id": "IaAw9Z3w0WjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Test prompt variations\n",
        "try:\n",
        "    print(\"\\nTesting prompt variations...\")\n",
        "\n",
        "    # Base prompt\n",
        "    base_prompt = \"A forest\"\n",
        "\n",
        "    # Create variations manually (to avoid NLTK complexity)\n",
        "    variations = [\n",
        "        f\"{base_prompt}, photorealistic, high quality\",\n",
        "        f\"{base_prompt}, digital art style, vibrant colors\",\n",
        "        f\"{base_prompt}, oil painting, masterpiece\"\n",
        "    ]\n",
        "\n",
        "    # Display the variations\n",
        "    for i, var in enumerate(variations):\n",
        "        print(f\"Variation {i+1}: {var}\")\n",
        "\n",
        "    # Generate just the first variation to demonstrate\n",
        "    print(f\"Generating image for variation 1...\")\n",
        "    optimize_memory()\n",
        "\n",
        "    var_image = pipe(\n",
        "        prompt=variations[0],\n",
        "        negative_prompt=create_negative_prompt(),\n",
        "        num_inference_steps=20,\n",
        "        height=384,\n",
        "        width=384\n",
        "    ).images[0]\n",
        "\n",
        "    save_image(var_image, images_dir, filename=\"prompt_variation.png\", prompt=variations[0])\n",
        "    display(var_image)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Prompt variation test failed: {e}\")"
      ],
      "metadata": {
        "id": "yhuUDl8t1a8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Explores Different Prompts:** This code tests how different text prompts affect the generated images.\n",
        "* **Prompt Variations:** It creates several variations of a base prompt (e.g., \"A forest\") by adding different artistic styles or descriptive words.\n",
        "* **Demonstration:** The code then generates and displays an image using the first prompt variation to demonstrate the effect of the changes.\n",
        "* **Error Handling:** Includes a try...except block to catch any potential errors during the image generation process."
      ],
      "metadata": {
        "id": "vVubNwEI00eM"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2sGbT38IlaOyUp45jqmHi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanikaa1010/Stable-diffusion-portfolio/blob/main/notebooks/SD_V3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# SD_V3.1.1"
      ],
      "metadata": {
        "id": "WmPkYGtczati"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PIP Installs\n",
        "\n",
        "!pip install -q huggingface_hub==0.16.4 diffusers==0.21.4 transformers==4.32.1 accelerate==0.21.0 torch==2.0.1\n",
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 diffusers transformers accelerate numpy --upgrade\n"
      ],
      "metadata": {
        "id": "YPBFxdPL2qwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37fc23e-b1ee-4e78-e9f1-2b3950597877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.21.4)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.32.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Collecting huggingface-hub>=0.27.0 (from diffusers)\n",
            "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting hf-xet<2.0.0,>=1.1.0 (from huggingface-hub>=0.27.0->diffusers)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.4.26)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m685.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m805.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.3/484.3 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, hf-xet, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, torch, tokenizers, diffusers, transformers, torchvision, accelerate\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.7.91\n",
            "    Uninstalling nvidia-nvtx-cu11-11.7.91:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.7.91\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.14.3\n",
            "    Uninstalling nvidia-nccl-cu11-2.14.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.14.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.4.91\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.4.91:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.4.91\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.2.10.91\n",
            "    Uninstalling nvidia-curand-cu11-10.2.10.91:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.2.10.91\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.7.101\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.7.101:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.7.101\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
            "    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs AI Tools: This code downloads and sets up essential Python libraries (like diffusers and transformers) often used for running AI models."
      ],
      "metadata": {
        "id": "TfFS7UUWr0u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title   Import libraries and define basic functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Memory optimization function\n",
        "def optimize_memory():\n",
        "    \"\"\"Free up GPU memory\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    print(\"Memory optimized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "b6656c58fc844afa9a7f9814573ed3a0",
            "c6c3f47fde8b4de681024a83ca38767b",
            "0a8e71a1375847c9afd316b5801fda97",
            "b19eacbaa78b48f28746d0a341e54254",
            "c44c4d19cf6440b09a6afd7785e7ff9f",
            "8afca14b13a546f7b3a81fc81097c92f",
            "3318b996cb05435a850210998421b5b2",
            "5beea607f2a041029c53c5291bacb8a8",
            "5d51a928d5474b8283c5cde8251c74a6",
            "10e7adaa06d841d48ddf6c6d6e8fa6cf",
            "23a3d20b19c14dc8a171dbc00d53658d"
          ]
        },
        "id": "SBAgi9AS1OaF",
        "outputId": "e6adb202-1d89-4ac0-824c-302b9ed0dbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6656c58fc844afa9a7f9814573ed3a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Sets up for AI Tasks**: The code imports various tools and libraries like torch (for AI computations), PIL (for images), and nltk (for text processing), and defines a function to free up memory.\n",
        "* **Downloads Data**: It downloads necessary data for the nltk library, used for text analysis.\n",
        "* **Memory Management**: It includes a function optimize_memory to clear up GPU memory, which is useful when working with large AI models to prevent crashes.\n",
        "\n"
      ],
      "metadata": {
        "id": "VFIme9Pcstw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Stable Diffusion with memory optimizations\n",
        "def initialize_stable_diffusion():\n",
        "    # Create directories\n",
        "    project_dir = \"./sd_project\"\n",
        "    images_dir = os.path.join(project_dir, \"images\")\n",
        "    os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "    # Determine device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load the model with memory optimization\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        revision=\"fp16\" if device == \"cuda\" else \"main\",\n",
        "        use_safetensors=True,\n",
        "    )\n",
        "\n",
        "    # Apply memory optimizations\n",
        "    if device == \"cuda\":\n",
        "        pipe.enable_attention_slicing(1)  # Slice attention to reduce memory\n",
        "\n",
        "    # Move to device\n",
        "    pipe = pipe.to(device)\n",
        "\n",
        "    print(\"Model loaded successfully\")\n",
        "    return pipe, images_dir\n",
        "\n",
        "# Initialize model\n",
        "pipe, images_dir = initialize_stable_diffusion()"
      ],
      "metadata": {
        "id": "G384vz-t1Rqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Loads AI Image Generator: Sets up the Stable Diffusion model to generate images from text prompts using pre-trained weights.\n",
        "\n",
        "⚙️ Device Selection: Automatically chooses GPU (if available) for faster processing, otherwise falls back to CPU.\n",
        "\n",
        "💾 Memory Optimization: Uses attention slicing — a technique that splits attention computation into tiny parts *(slicing=1)* to save GPU memory at the cost of a bit of speed. This is essential for running large models on limited hardware.\n",
        "\n",
        "🚀 Ready to Use: The function returns a ready pipeline and a folder path to save generated images."
      ],
      "metadata": {
        "id": "p73Buzpntpzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Create a simplified prompt enhancer\n",
        "def enhance_prompt(prompt, quality_level=\"high\"):\n",
        "    \"\"\"Enhance a prompt with quality descriptors\"\"\"\n",
        "    quality_descriptors = {\n",
        "        \"low\": \"good quality\",\n",
        "        \"medium\": \"high quality, detailed\",\n",
        "        \"high\": \"high quality, detailed, sharp focus, 8k\",\n",
        "        \"ultra\": \"masterpiece, best quality, ultra detailed, 8k HDR, sharp focus\"\n",
        "    }\n",
        "\n",
        "    # Get quality descriptor\n",
        "    quality = quality_descriptors.get(quality_level, quality_descriptors[\"high\"])\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced = f\"{prompt}, {quality}\"\n",
        "    return enhanced\n",
        "\n",
        "# Create a simplified negative prompt generator\n",
        "def create_negative_prompt():\n",
        "    \"\"\"Create a standard negative prompt\"\"\"\n",
        "    return (\"deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, \"\n",
        "            \"extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, \"\n",
        "            \"ugly, disgusting, blurry, low quality\")"
      ],
      "metadata": {
        "id": "gBpCk1451TQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Improves Prompts:** The code defines functions to enhance the text prompts given to the AI model.\n",
        "* **Quality Levels:** The enhance_prompt function adds quality descriptors (like \"high quality\" or \"8k\") based on the chosen level.\n",
        "* **Negative Prompts:** The create_negative_prompt function generates a standard \"negative prompt\" (things to avoid in the image, like deformities) to improve image quality."
      ],
      "metadata": {
        "id": "O-0angwcvOPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Basic image generation function\n",
        "def generate_image(pipe, prompt, negative_prompt=None, steps=30, guidance=7.5, height=512, width=512):\n",
        "    \"\"\"Generate an image with Stable Diffusion\"\"\"\n",
        "\n",
        "    # Use default negative prompt if none provided\n",
        "    if negative_prompt is None:\n",
        "        negative_prompt = create_negative_prompt()\n",
        "\n",
        "    # Optimize memory before generation\n",
        "    optimize_memory()\n",
        "\n",
        "    # Generate image\n",
        "    start_time = time.time()\n",
        "    print(f\"Generating image with {steps} steps...\")\n",
        "\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "        height=height,\n",
        "        width=width\n",
        "    ).images[0]\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Image generated in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    return image\n",
        "\n",
        "# Save image function\n",
        "def save_image(image, images_dir, filename=None, prompt=None):\n",
        "    \"\"\"Save an image with optional metadata\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"image_{timestamp}.png\"\n",
        "\n",
        "    save_path = os.path.join(images_dir, filename)\n",
        "    image.save(save_path)\n",
        "\n",
        "    # Save prompt as text file if provided\n",
        "    if prompt:\n",
        "        text_path = save_path.replace('.png', '_prompt.txt')\n",
        "        with open(text_path, 'w') as f:\n",
        "            f.write(prompt)\n",
        "\n",
        "    print(f\"Image saved to {save_path}\")\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "fI2_z0Kh1UfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Generates Images:** The code defines a generate_image function that takes a text prompt and uses the Stable Diffusion model to create an image.\n",
        "* **Customization:** You can control image generation with parameters like the number of steps, image size, and how closely the image should match the prompt. It also uses a negative prompt to specify what to avoid in the image.\n",
        "* **Memory Optimization:** It calls optimize_memory before generating each image.\n",
        "* **Saves Images:** The save_image function saves the generated images to a specified directory, optionally including the original prompt in a text file."
      ],
      "metadata": {
        "id": "KneR7iKnz11E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test single image generation\n",
        "try:\n",
        "    # Use a simple prompt\n",
        "    prompt = \"A small cottage in the forest\"\n",
        "    print(f\"Original prompt: {prompt}\")\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced_prompt = enhance_prompt(prompt, \"medium\")  # Medium for less complexity\n",
        "    print(f\"Enhanced prompt: {enhanced_prompt}\")\n",
        "\n",
        "    # Generate negative prompt\n",
        "    negative_prompt = create_negative_prompt()\n",
        "    print(f\"Using standard negative prompt\")\n",
        "\n",
        "    # Generate image (with small size for testing)\n",
        "    image = generate_image(\n",
        "        pipe=pipe,\n",
        "        prompt=enhanced_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        steps=20,  # Lower steps for quicker generation\n",
        "        height=384,  # Smaller size to conserve memory\n",
        "        width=384\n",
        "    )\n",
        "\n",
        "    # Save and display the image\n",
        "    save_image(image, images_dir, prompt=enhanced_prompt)\n",
        "    from IPython.display import display\n",
        "    display(image)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in image generation: {e}\")\n",
        "\n",
        "    # If it fails, try with absolute minimal settings\n",
        "    try:\n",
        "        print(\"Attempting with minimal settings...\")\n",
        "        optimize_memory()\n",
        "\n",
        "        minimal_image = pipe(\n",
        "            prompt=\"Forest cottage\",\n",
        "            num_inference_steps=15,\n",
        "            height=256,\n",
        "            width=256\n",
        "        ).images[0]\n",
        "\n",
        "        save_image(minimal_image, images_dir, filename=\"minimal_test.png\")\n",
        "        display(minimal_image)\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"Even minimal settings failed: {e2}\")\n",
        "        print(\"Your Colab environment may not have enough GPU resources for Stable Diffusion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lASsc4Ev1XBE",
        "outputId": "49b6db2e-aba4-467e-e925-548c59bd8b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original prompt: A small cottage in the forest\n",
            "Enhanced prompt: A small cottage in the forest, high quality, detailed\n",
            "Using standard negative prompt\n",
            "Error in image generation: name 'pipe' is not defined\n",
            "Attempting with minimal settings...\n",
            "Memory optimized\n",
            "Even minimal settings failed: name 'pipe' is not defined\n",
            "Your Colab environment may not have enough GPU resources for Stable Diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Tests Image Generation:** This code block attempts to generate and display a single image using the defined functions.\n",
        "* **Prompt Enhancement:** It uses the enhance_prompt function to improve the initial prompt.\n",
        "* **Error Handling:** If the initial image generation fails (due to memory issues or other problems), it tries again with much simpler settings to ensure the core functionality works.\n",
        "* **Image Display:** It saves the generated image and displays it within the environment (like a Jupyter Notebook or Google Colab)."
      ],
      "metadata": {
        "id": "Ie2Uy1MG0JfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Simple parameter comparison\n",
        "# Only run this if Step 6 succeeded\n",
        "\n",
        "try:\n",
        "    print(\"\\nCreating simple parameter comparison...\")\n",
        "    optimize_memory()\n",
        "\n",
        "    # Use a very simple prompt\n",
        "    simple_prompt = \"Mountain landscape\"\n",
        "\n",
        "    # Test different step counts (keeping everything else minimal)\n",
        "    steps_to_test = [15, 30]\n",
        "    images = []\n",
        "\n",
        "    for steps in steps_to_test:\n",
        "        print(f\"Generating with {steps} steps...\")\n",
        "        img = pipe(\n",
        "            prompt=simple_prompt,\n",
        "            negative_prompt=create_negative_prompt(),\n",
        "            num_inference_steps=steps,\n",
        "            height=384,\n",
        "            width=384\n",
        "        ).images[0]\n",
        "\n",
        "        images.append(img)\n",
        "        save_image(img, images_dir, filename=f\"steps_{steps}.png\")\n",
        "\n",
        "    # Display comparison\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 6))\n",
        "\n",
        "    for i, (img, steps) in enumerate(zip(images, steps_to_test)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Steps: {steps}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(images_dir, \"steps_comparison.png\"))\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Parameter comparison failed: {e}\")\n",
        "    print(\"Try running with even smaller settings or on CPU\")"
      ],
      "metadata": {
        "id": "382ZgQFo1YiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Compares Image Quality:** This code tests how different settings (specifically, the number of steps) affect the quality of the generated images.\n",
        "* **Iterative Generation:** It generates multiple images using the same prompt but with varying numbers of \"steps\" (a setting that affects image quality).\n",
        "* **Visual Comparison:** It then displays these generated images side-by-side using Matplotlib, making it easy to see the impact of changing the \"steps\" parameter.\n",
        "* **Error Handling:** Includes a try...except block to handle potential issues during image generation and provides suggestions for troubleshooting."
      ],
      "metadata": {
        "id": "IaAw9Z3w0WjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Test prompt variations\n",
        "try:\n",
        "    print(\"\\nTesting prompt variations...\")\n",
        "\n",
        "    # Base prompt\n",
        "    base_prompt = \"A forest\"\n",
        "\n",
        "    # Create variations manually (to avoid NLTK complexity)\n",
        "    variations = [\n",
        "        f\"{base_prompt}, photorealistic, high quality\",\n",
        "        f\"{base_prompt}, digital art style, vibrant colors\",\n",
        "        f\"{base_prompt}, oil painting, masterpiece\"\n",
        "    ]\n",
        "\n",
        "    # Display the variations\n",
        "    for i, var in enumerate(variations):\n",
        "        print(f\"Variation {i+1}: {var}\")\n",
        "\n",
        "    # Generate just the first variation to demonstrate\n",
        "    print(f\"Generating image for variation 1...\")\n",
        "    optimize_memory()\n",
        "\n",
        "    var_image = pipe(\n",
        "        prompt=variations[0],\n",
        "        negative_prompt=create_negative_prompt(),\n",
        "        num_inference_steps=20,\n",
        "        height=384,\n",
        "        width=384\n",
        "    ).images[0]\n",
        "\n",
        "    save_image(var_image, images_dir, filename=\"prompt_variation.png\", prompt=variations[0])\n",
        "    display(var_image)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Prompt variation test failed: {e}\")"
      ],
      "metadata": {
        "id": "yhuUDl8t1a8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Explores Different Prompts:** This code tests how different text prompts affect the generated images.\n",
        "* **Prompt Variations:** It creates several variations of a base prompt (e.g., \"A forest\") by adding different artistic styles or descriptive words.\n",
        "* **Demonstration:** The code then generates and displays an image using the first prompt variation to demonstrate the effect of the changes.\n",
        "* **Error Handling:** Includes a try...except block to catch any potential errors during the image generation process."
      ],
      "metadata": {
        "id": "vVubNwEI00eM"
      }
    }
  ]
}
